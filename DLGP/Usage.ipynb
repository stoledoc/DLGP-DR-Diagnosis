{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage of DLGP for DR diagnosis\n",
    "\n",
    "We are going to use the DLGP to diagnose diabetic retinopathy in a single eye fundus image. Besides the diagnosis, the model also returns an uncertainty measure. \n",
    "\n",
    "First, the preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#\n",
    "# Functions for preprocessing image.\n",
    "#\n",
    "########################################################################\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from pylab import array, arange, uint8\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "import h5py\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def _increase_contrast(image):\n",
    "\n",
    "    # Create a local copy of the image.\n",
    "    copy = image.copy()\n",
    "\n",
    "    maxIntensity = 255.0\n",
    "    x = arange(maxIntensity)\n",
    "\n",
    "    # Parameters for manipulating image data.\n",
    "    phi = 1.3\n",
    "    theta = 1.5\n",
    "    y = (maxIntensity/phi)*(x/(maxIntensity/theta))**0.5\n",
    "\n",
    "    # Decrease intensity such that dark pixels become much darker,\n",
    "    # and bright pixels become slightly dark.\n",
    "    copy = (maxIntensity/phi)*(copy/(maxIntensity/theta))**2\n",
    "    copy = array(copy, dtype=uint8)\n",
    "\n",
    "    return copy\n",
    "\n",
    "\n",
    "def _find_contours(image):\n",
    "\n",
    "    # Increase constrast in image to increase changes of finding\n",
    "    # contours.\n",
    "    processed = _increase_contrast(image)\n",
    "\n",
    "    # Get the gray-scale of the image.\n",
    "    gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect contour(s) in the image.\n",
    "    cnts = cv2.findContours(\n",
    "        gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = None\n",
    "\n",
    "    # At least ensure that some contours were found.\n",
    "    if len(cnts) > 0:\n",
    "        # Find the largest contour in the mask.\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "\n",
    "        # Assume the radius is of a certain size.\n",
    "        if radius > 100:\n",
    "            M = cv2.moments(c)\n",
    "            center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "            return (center, radius)\n",
    "\n",
    "\n",
    "def _get_filename(file_path):\n",
    "\n",
    "    return file_path.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "def _resize_and_center_fundus(image, diameter):\n",
    "\n",
    "    copy = image.copy()\n",
    "\n",
    "    # Find largest contour in image.\n",
    "    contours = _find_contours(image)\n",
    "\n",
    "    # Return unless we have gotten some result contours.\n",
    "    if contours is None:\n",
    "        return None\n",
    "\n",
    "    center, radius = contours\n",
    "\n",
    "    # Calculate the min and max-boundaries for cropping the image.\n",
    "    x_min = max(0, int(center[0] - radius))\n",
    "    y_min = max(0, int(center[1] - radius))\n",
    "    z = int(radius*2)\n",
    "    x_max = x_min + z\n",
    "    y_max = y_min + z\n",
    "\n",
    "    # Crop the image.\n",
    "    copy = copy[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Scale the image.\n",
    "    fx = fy = (diameter / 2) / radius\n",
    "    copy = cv2.resize(copy, (0, 0), fx=fx, fy=fy)\n",
    "\n",
    "    # Add padding to image.\n",
    "    shape = copy.shape\n",
    "\n",
    "    # Get the border shape size.\n",
    "    top = bottom = int((diameter - shape[0])/2)\n",
    "    left = right = int((diameter - shape[1])/2)\n",
    "\n",
    "    # Add 1 pixel if necessary.\n",
    "    if shape[0] + top + bottom == diameter - 1:\n",
    "        top += 1\n",
    "\n",
    "    if shape[1] + left + right == diameter - 1:\n",
    "        left += 1\n",
    "\n",
    "    # Define border of the image.\n",
    "    border = [top, bottom, left, right]\n",
    "\n",
    "    # Add border.\n",
    "    copy = cv2.copyMakeBorder(copy, *border,\n",
    "                              borderType=cv2.BORDER_CONSTANT,\n",
    "                              value=[0, 0, 0])\n",
    "    # Return the image.\n",
    "    return copy\n",
    "\n",
    "\n",
    "def _get_image_paths(images_path):\n",
    "  \n",
    "    return [os.path.join(images_path, fn) for fn in os.listdir(images_path)]\n",
    "\n",
    "\n",
    "def _resize_and_center_fundus_all(image_paths, save_path, diameter, verbosity):\n",
    "    # Get the total amount of images.\n",
    "    num_images = len(image_paths)\n",
    "    success = 0\n",
    "\n",
    "    # For each image in the specified directory.\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        if verbosity > 0:\n",
    "            # Status-message.\n",
    "            msg = \"\\r- Preprocessing image: {0:>6} / {1}\".format(\n",
    "                    i+1, num_images)\n",
    "\n",
    "            # Print the status message.\n",
    "            sys.stdout.write(msg)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        try:\n",
    "            # Load the image and clone it for output.\n",
    "            image = cv2.imread(os.path.abspath(image_path), -1)\n",
    "\n",
    "            processed = _resize_and_center_fundus(image, diameter=diameter)\n",
    "\n",
    "            if processed is None:\n",
    "                print(\"Could not preprocess {}...\".format(image_path))\n",
    "            else:\n",
    "                # Get the save path for the processed image.\n",
    "                image_filename = _get_filename(image_path)\n",
    "                image_jpeg_filename = \"{0}.jpg\".format(os.path.splitext(\n",
    "                                        os.path.basename(image_filename))[0])\n",
    "                output_path = os.path.join(save_path, image_jpeg_filename)\n",
    "\n",
    "                # Save the image.\n",
    "                cv2.imwrite(output_path, processed,\n",
    "                            [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "\n",
    "                success += 1\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            print(\"Could not preprocess {}...\".format(image_path))\n",
    "\n",
    "    return success\n",
    "\n",
    "\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def resize_and_center_fundus(save_path=None, images_path=None, image_paths=None,\n",
    "                    image_path=None, diameter=299, verbosity=1):\n",
    "    \n",
    "    if save_path is None:\n",
    "        raise ValueError(\"Save path not specified!\")\n",
    "\n",
    "    save_path = os.path.abspath(save_path)\n",
    "\n",
    "    if image_paths is not None:\n",
    "        return _resize_and_center_fundus_all(image_paths=image_paths,\n",
    "                                             save_path=save_path,\n",
    "                                             diameter=diameter,\n",
    "                                             verbosity=verbosity)\n",
    "\n",
    "    elif images_path is not None:\n",
    "        # Get the paths to all images.\n",
    "        image_paths = _get_image_paths(images_path)\n",
    "        # Scale all images.\n",
    "        return _resize_and_center_fundus_all(image_paths=image_paths,\n",
    "                                             save_path=save_path,\n",
    "                                             diameter=diameter,\n",
    "                                             verbosity=verbosity)\n",
    "\n",
    "    elif image_path is not None:\n",
    "        return _resize_and_center_fundus_all(image_paths=[image_path],\n",
    "                                             save_path=save_path,\n",
    "                                             diameter=diameter,\n",
    "                                             verbosity=verbosity)\n",
    "\n",
    "\n",
    "def resize(images_paths, size=299):\n",
    "\n",
    "    for image_path in images_paths:\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # Resize the image.\n",
    "        image = cv2.resize(image, (size, size))\n",
    "\n",
    "        # Save the image.\n",
    "        cv2.imwrite(image_path, image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "\n",
    "\n",
    "def rescale_min_1_to_1(image):\n",
    "\n",
    "    # Image must be casted to float32 first.\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    # Rescale image from [0, 255] to [0, 2].\n",
    "    image = tf.multiply(image, 1. / 127.5)\n",
    "    # Rescale to [-1, 1].\n",
    "    return tf.subtract(image, 1.0)\n",
    "\n",
    "\n",
    "def rescale_0_to_1(image):\n",
    "\n",
    "    return tf.image.convert_image_dtype(image, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/home/santiagotc/Documents/MindLab/DLGP-DR-Diagnosis/data/non_preprocessed' #path where the preprocessed image will be saved\n",
    "images_path = '/home/santiagotc/Documents/MindLab/DLGP-DR-Diagnosis/data/preprocessed/' #single path to the original image\n",
    "\n",
    "resize_and_center_fundus(save_path=save_path, \n",
    "                         images_path=images_path, #Optional. Path to directory where images reside in.\n",
    "                         image_paths=None, #Optional. List of paths to images.\n",
    "                         image_path=None, \n",
    "                         diameter=299, \n",
    "                         verbosity=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DLGP\n",
    "\n",
    "Then, the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_DIR = images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras import losses\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "import h5py\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "input_tensor = Input(shape=(299, 299,3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "base_model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=False, pooling='avg')\n",
    "x = base_model.output\n",
    "x = Dense(2048, activation = 'relu')(x)\n",
    "predictions = Dense(1, activation = 'sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "optimizer = tf.keras.optimizers.RMSprop()\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy',tf.keras.metrics.AUC()])\n",
    "model.load_weights('inceptionV3_keras_2_2.h5') # loading weights\n",
    "layer_name = 'dense_1' # defining output layer\n",
    "intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                       outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "batch_size = 1\n",
    "test_datagen = ImageDataGenerator(samplewise_center = True, rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "                                                    SAMPLE_DIR,\n",
    "                                                    target_size=(299, 299),  \n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "feature_vector = intermediate_layer_model.predict(test_generator) #using inception to extract feature vector\n",
    "\n",
    "gpr = load('gpr_kaggle_train_voets_inceptionv3_features_balanced_paper.joblib') #loading Gaussian process parameters\n",
    "y_pred, std = gpr.predict(feature_vector, return_std=True) # Predicting with Gaussian process\n",
    "\n",
    "if y_pred < 1.5: # Threshold to binarize the prediction\n",
    "    str1 = 'Negativo'\n",
    "    if std < 0.79:\n",
    "        str2 = 'Baja'\n",
    "    else:\n",
    "        str2 = 'Alta'\n",
    "else:\n",
    "    str1 = 'Positivo'\n",
    "    if std < 0.77:\n",
    "        str2 = 'Baja'\n",
    "    else:\n",
    "        str2 = 'Alta'\n",
    "        \n",
    "print('DiagnÃ³stico: ', str1, '- Incertidumbre: ',str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
